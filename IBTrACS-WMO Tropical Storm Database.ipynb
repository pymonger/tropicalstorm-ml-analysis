{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset header info courtesy of \"ncdump -h\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "netcdf Allstorms.ibtracs_wmo.v03r08 {\n",
    "dimensions:\n",
    "\tstorm = UNLIMITED ; // (7152 currently)\n",
    "\ttime = 142 ;\n",
    "\tncharsn = 13 ;\n",
    "\tncharnm = 57 ;\n",
    "\tcenter = 26 ;\n",
    "\tncharcn = 10 ;\n",
    "\n",
    "variables:\n",
    "\tchar storm_sn(storm, ncharsn) ;\n",
    "\t\tstorm_sn:long_name = \"Storm serial number\" ;\n",
    "\tchar name(storm, ncharnm) ;\n",
    "\t\tname:long_name = \"Storm name\" ;\n",
    "\tshort numObs(storm) ;\n",
    "\t\tnumObs:long_name = \"Number of observations for the storm\" ;\n",
    "\tshort season(storm) ;\n",
    "\t\tseason:long_name = \"Year based on season\" ;\n",
    "\t\tseason:Note = \"Following WMO,\\n\",\n",
    "    \"NH Seasons begin 1 January and \\n\",\n",
    "    \"SH Seasons begin 1 July the prior year\" ;\n",
    "\tbyte track_type(storm) ;\n",
    "\t\ttrack_type:long_name = \"Track type\" ;\n",
    "\t\ttrack_type:key = \"0 = main - cyclogenesis to cyclolysis\\n\",\n",
    "    \"1 = merge - cyclogenesis to merger\\n\",\n",
    "    \"2 = split - split to cyclolysis\\n\",\n",
    "    \"3 = other - split to merger\" ;\n",
    "\tbyte genesis_basin(storm) ;\n",
    "\t\tgenesis_basin:long_name = \"Basin of genesis\" ;\n",
    "\t\tgenesis_basin:units = \" \" ;\n",
    "\t\tgenesis_basin:key = \"0 = NA - North Atlantic\\n\",\n",
    "    \"1 = SA - South Atlantic\\n\",\n",
    "    \"2 = WP - West Pacific\\n\",\n",
    "    \"3 = EP - East Pacific\\n\",\n",
    "    \"4 = SP - South Pacific\\n\",\n",
    "    \"5 = NI - North Indian\\n\",\n",
    "    \"6 = SI - South Indian\\n\",\n",
    "    \"7 = AS - Arabian Sea\\n\",\n",
    "    \"8 = BB - Bay of Bengal\\n\",\n",
    "    \"9 = EA - Eastern Australia\\n\",\n",
    "    \"10 = WA - Western Australia\\n\",\n",
    "    \"11 = CP - Central Pacific\\n\",\n",
    "    \"12 = CS - Carribbean Sea\\n\",\n",
    "    \"13 = GM - Gulf of Mexico\\n\",\n",
    "    \"14 = MM - Missing\" ;\n",
    "\t\tgenesis_basin:Note = \"Based on where the storm began\" ;\n",
    "\tbyte num_basins(storm) ;\n",
    "\t\tnum_basins:long_name = \"Number of basins through which the storm passes\" ;\n",
    "\t\tnum_basins:units = \" \" ;\n",
    "\tbyte basin(storm, time) ;\n",
    "\t\tbasin:long_name = \"Basin\" ;\n",
    "\t\tbasin:units = \" \" ;\n",
    "\t\tbasin:key = \"0 = NA - North Atlantic\\n\",\n",
    "    \"1 = SA - South Atlantic\\n\",\n",
    "    \"2 = WP - West Pacific\\n\",\n",
    "    \"3 = EP - East Pacific\\n\",\n",
    "    \"4 = SP - South Pacific\\n\",\n",
    "    \"5 = NI - North Indian\\n\",\n",
    "    \"6 = SI - South Indian\\n\",\n",
    "    \"7 = AS - Arabian Sea\\n\",\n",
    "    \"8 = BB - Bay of Bengal\\n\",\n",
    "    \"9 = EA - Eastern Australia\\n\",\n",
    "    \"10 = WA - Western Australia\\n\",\n",
    "    \"11 = CP - Central Pacific\\n\",\n",
    "    \"12 = CS - Carribbean Sea\\n\",\n",
    "    \"13 = GM - Gulf of Mexico\\n\",\n",
    "    \"14 = MM - Missing\" ;\n",
    "\t\tbasin:Note = \"Based on present location\" ;\n",
    "\t\tbasin:_FillValue = '\\201' ;\n",
    "\tbyte wind_avg_period(center) ;\n",
    "\t\twind_avg_period:long_name = \"Wind speed averaging period\" ;\n",
    "\t\twind_avg_period:units = \"min\" ;\n",
    "\t\twind_avg_period:_FillValue = '\\201' ;\n",
    "\tchar source(center, ncharcn) ;\n",
    "\t\tsource:long_name = \"Source name\" ;\n",
    "\t\tsource:Note = \"This order matches the dimension in source_* variables\" ;\n",
    "\tdouble time_wmo(storm, time) ;\n",
    "\t\ttime_wmo:long_name = \"Modified Julian Day\" ;\n",
    "\t\ttime_wmo:units = \"days since 1858-11-17 00:00:00\" ;\n",
    "\t\ttime_wmo:_FillValue = 9.969209999999999e+36 ;\n",
    "\tshort lat_wmo(storm, time) ;\n",
    "\t\tlat_wmo:long_name = \"Storm center latitude\" ;\n",
    "\t\tlat_wmo:units = \"degrees_north\" ;\n",
    "\t\tlat_wmo:scale_factor = 0.0099999998f ;\n",
    "\t\tlat_wmo:_FillValue = -32767s ;\n",
    "\tshort lon_wmo(storm, time) ;\n",
    "\t\tlon_wmo:long_name = \"Storm center longitude\" ;\n",
    "\t\tlon_wmo:units = \"degrees_east\" ;\n",
    "\t\tlon_wmo:scale_factor = 0.0099999998f ;\n",
    "\t\tlon_wmo:_FillValue = -32767s ;\n",
    "\tbyte alt(storm, time) ;\n",
    "\t\talt:long_name = \"Altitude\" ;\n",
    "\t\talt:units = \"m\" ;\n",
    "\t\talt:_FillValue = '\\201' ;\n",
    "\t\talt:note = \"only included in an attempt to have THREDDS recognize the file as a trajectory\" ;\n",
    "\tshort wind_wmo(storm, time) ;\n",
    "\t\twind_wmo:long_name = \"Maximum Sustained Wind (MSW)\" ;\n",
    "\t\twind_wmo:units = \"kt\" ;\n",
    "\t\twind_wmo:scale_factor = 0.1f ;\n",
    "\t\twind_wmo:_FillValue = -32767s ;\n",
    "\tshort pres_wmo(storm, time) ;\n",
    "\t\tpres_wmo:long_name = \"Minimum Central Pressure (MCP)\" ;\n",
    "\t\tpres_wmo:units = \"mb\" ;\n",
    "\t\tpres_wmo:scale_factor = 0.1f ;\n",
    "\t\tpres_wmo:_FillValue = -32767s ;\n",
    "\tbyte sub_basin(storm, time) ;\n",
    "\t\tsub_basin:long_name = \"Sub-Basin\" ;\n",
    "\t\tsub_basin:units = \" \" ;\n",
    "\t\tsub_basin:key = \"0 = NA - North Atlantic\\n\",\n",
    "    \"1 = SA - South Atlantic\\n\",\n",
    "    \"2 = WP - West Pacific\\n\",\n",
    "    \"3 = EP - East Pacific\\n\",\n",
    "    \"4 = SP - South Pacific\\n\",\n",
    "    \"5 = NI - North Indian\\n\",\n",
    "    \"6 = SI - South Indian\\n\",\n",
    "    \"7 = AS - Arabian Sea\\n\",\n",
    "    \"8 = BB - Bay of Bengal\\n\",\n",
    "    \"9 = EA - Eastern Australia\\n\",\n",
    "    \"10 = WA - Western Australia\\n\",\n",
    "    \"11 = CP - Central Pacific\\n\",\n",
    "    \"12 = CS - Carribbean Sea\\n\",\n",
    "    \"13 = GM - Gulf of Mexico\\n\",\n",
    "    \"14 = MM - Missing\" ;\n",
    "\t\tsub_basin:Note = \"Based on present location\" ;\n",
    "\t\tsub_basin:_FillValue = '\\201' ;\n",
    "\tbyte nature_wmo(storm, time) ;\n",
    "\t\tnature_wmo:long_name = \"Storm nature\" ;\n",
    "\t\tnature_wmo:key = \"0 = TS - Tropical\\n\",\n",
    "    \"1 = SS - Subtropical\\n\",\n",
    "    \"2 = ET - Extratropical\\n\",\n",
    "    \"3 = DS - Disturbance\\n\",\n",
    "    \"4 = MX - Mix of conflicting reports\\n\",\n",
    "    \"5 = NR - Not Reported\\n\",\n",
    "    \"6 = MM - Missing\\n\",\n",
    "    \"7 =  - Missing\" ;\n",
    "\t\tnature_wmo:Note = \"Based on classification from original sources\" ;\n",
    "\t\tnature_wmo:_FillValue = '\\201' ;\n",
    "\tbyte source_wmo(storm, time) ;\n",
    "\t\tsource_wmo:long_name = \"Source used as WMO agency\" ;\n",
    "\t\tsource_wmo:flag_values = \"0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\" ;\n",
    "\t\tsource_wmo:flag_meanings = \"hurdat_atl td9636 reunion atcf mlc_natl ds824_sh ds824_ni bom ds824_au jtwc_sh jtwc_wp td9635 ds824_wp jtwc_io cma hurdat_epa jtwc_ep ds824_ep jtwc_cp tokyo neumann hko cphc wellington newdelhi nadi\" ;\n",
    "\t\tsource_wmo:_FillValue = '\\201' ;\n",
    "\tshort dist2land(storm, time) ;\n",
    "\t\tdist2land:long_name = \"Distance to land\" ;\n",
    "\t\tdist2land:units = \"km\" ;\n",
    "\t\tdist2land:_FillValue = -999s ;\n",
    "\tshort landfall(storm, time) ;\n",
    "\t\tlandfall:long_name = \"Minimum distance to land until next report (0=landfall)\" ;\n",
    "\t\tlandfall:units = \"km\" ;\n",
    "\t\tlandfall:_FillValue = -999s ;\n",
    "\n",
    "// global attributes:\n",
    "\t\t:Title = \"IBTrACS-WMO: NetCDF reformat\" ;\n",
    "\t\t:Version = \"v03r08\" ;\n",
    "\t\t:Description = \"IBTrACS-WMO data reformatted to contain \\n\",\n",
    "    \"all data in one netCDF file. Also an attempt has been made\\n\",\n",
    "    \"to have the data appear as trajectories in the CDM\" ;\n",
    "\t\t:cdm_datatype = \"Trajectory\" ;\n",
    "\t\t:trajectoryDimension = \"storm\" ;\n",
    "\t\t:Conventions = \"CF-1.0\" ;\n",
    "\t\t:metadata_link = \"gov.noaa.ncdc:C00834\" ;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the storm dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from subprocess import check_output\n",
    "import netCDF4 as NC\n",
    "import numpy as np\n",
    "\n",
    "file = \"Allstorms.ibtracs_wmo.v03r08.nc\"\n",
    "ds = NC.Dataset(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get the last 500 storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: BLANCA\n",
      "1: SOUDELOR\n",
      "2: CARLOS\n",
      "3: DOLORES\n",
      "4: MOLAVE\n",
      "5: NOT NAMED\n",
      "6: LANA\n",
      "7: GONI\n",
      "8: FELICIA\n",
      "9: ENRIQUE\n",
      "10: MORAKOT\n",
      "11: ETAU\n",
      "12: NINE\n",
      "13: MAKA:TD0813\n",
      "14: GUILLERMO\n",
      "15: ANA\n",
      "16: BILL\n",
      "17: VAMCO\n",
      "18: CLAUDETTE\n",
      "19: HILDA\n",
      "20: IGNACIO\n",
      "21: TD0830:TWO:TWO_C\n",
      "22: KROVANH\n",
      "23: KEVIN\n",
      "24: JIMENA\n",
      "25: DANNY\n",
      "26: ERIKA\n",
      "27: LINDA\n",
      "28: DUJUAN\n",
      "29: NOT NAMED\n",
      "30: FRED\n",
      "31: MUJIGAE\n",
      "32: KOPPU\n",
      "33: CHOI-WAN\n",
      "34: MARTY\n",
      "35: NORA\n",
      "36: KETSANA\n",
      "37: EIGHT\n",
      "38: PARMA\n",
      "39: OLAF\n",
      "40: GRACE\n",
      "41: MELOR\n",
      "42: HENRI\n",
      "43: NEPARTAK\n",
      "44: PATRICIA\n",
      "45: LUPIT\n",
      "46: RICK\n",
      "47: NEKI\n",
      "48: MIRINAE\n",
      "49: IDA\n",
      "50: PHYAN\n",
      "51: ANJA\n",
      "52: NIDA\n",
      "53: BONGANI\n",
      "54: CLEO\n",
      "55: LAURENCE\n",
      "56: WARD\n",
      "57: DAVID\n",
      "58: MICK\n",
      "59: EDZANI\n",
      "60: NONAME\n",
      "61: MAGDA\n",
      "62: NEVILLE\n",
      "63: OLGA\n",
      "64: NISHA\n",
      "65: OLI\n",
      "66: FAMI\n",
      "67: PAT\n",
      "68: RENE\n",
      "69: GELANE\n",
      "70: SARAH:SEVENTEEN\n",
      "71: HUBERT\n",
      "72: INVEST\n",
      "73: TOMAS\n",
      "74: ULUI\n",
      "75: OMAIS\n",
      "76: IMANI\n",
      "77: PAUL\n",
      "78: ROBYN\n",
      "79: SEAN\n",
      "80: BANDU\n",
      "81: LAILA\n",
      "82: JOEL\n",
      "83: AGATHA\n",
      "84: PHET\n",
      "85: BLAS\n",
      "86: TWO\n",
      "87: CELIA\n",
      "88: DARBY\n",
      "89: ALEX\n",
      "90: TWO\n",
      "91: CONSON\n",
      "92: SIX\n",
      "93: CHANTHU\n",
      "94: BONNIE\n",
      "95: COLIN\n",
      "96: ESTELLE\n",
      "97: DIANMU\n",
      "98: FIVE\n",
      "99: EIGHT\n",
      "100: MINDULLE\n",
      "101: DANIELLE\n",
      "102: FRANK\n",
      "103: EARL\n",
      "104: LIONROCK\n",
      "105: KOMPASU\n",
      "106: NAMTHEUN\n",
      "107: FIONA\n",
      "108: MALOU\n",
      "109: GASTON\n",
      "110: TEN\n",
      "111: ELEVEN:HERMINE\n",
      "112: MERANTI\n",
      "113: IGOR\n",
      "114: JULIA\n",
      "115: FANAPI\n",
      "116: KARL\n",
      "117: MALAKAS\n",
      "118: LISA\n",
      "119: GEORGETTE\n",
      "120: MATTHEW\n",
      "121: NICOLE\n",
      "122: OTTO\n",
      "123: NOT NAMED\n",
      "124: PAULA\n",
      "125: MEGI\n",
      "126: NOT NAMED\n",
      "127: CHABA\n",
      "128: GIRI\n",
      "129: RICHARD\n",
      "130: TOMAS\n",
      "131: SHARY\n",
      "132: ANGGREK\n",
      "133: JAL\n",
      "134: ABELE\n",
      "135: NOT NAMED\n",
      "136: NONAME\n",
      "137: OMEKA:TD1219\n",
      "138: TASHA\n",
      "139: NONAME\n",
      "140: VINCE\n",
      "141: VANIA\n",
      "142: ZELIA\n",
      "143: WILMA\n",
      "144: BIANCA\n",
      "145: ANTHONY\n",
      "146: YASI\n",
      "147: NOT NAMED\n",
      "148: ZAKA\n",
      "149: BINGIZA\n",
      "150: CARLOS\n",
      "151: DIANNE\n",
      "152: ATU\n",
      "153: INVEST\n",
      "154: CHERONO\n",
      "155: BUNE\n",
      "156: NONAME:TWENTY\n",
      "157: ERROL\n",
      "158: 0920102011\n",
      "159: AERE\n",
      "160: SONGDA\n",
      "161: ADRIAN\n",
      "162: SARIKA\n",
      "163: ONE\n",
      "164: HAIMA\n",
      "165: NOT NAMED\n",
      "166: BEATRIZ\n",
      "167: MEARI\n",
      "168: ARLENE\n",
      "169: CALVIN\n",
      "170: MA-ON\n",
      "171: TOKAGE\n",
      "172: BRET\n",
      "173: DORA\n",
      "174: CINDY\n",
      "175: NOT NAMED\n",
      "176: NOCK-TEN\n",
      "177: MUIFA\n",
      "178: DON\n",
      "179: EUGENE\n",
      "180: EMILY\n",
      "181: MERBOK\n",
      "182: GERT\n",
      "183: FRANKLIN\n",
      "184: FERNANDA\n",
      "185: GREG\n",
      "186: HARVEY\n",
      "187: NANMADOL\n",
      "188: IRENE\n",
      "189: TALAS\n",
      "190: TEN\n",
      "191: JOSE\n",
      "192: KATIA\n",
      "193: EIGHT\n",
      "194: NONAME:UNNAMED\n",
      "195: NORU\n",
      "196: LEE\n",
      "197: KULAP\n",
      "198: MARIA\n",
      "199: NATE\n",
      "200: ROKE\n",
      "201: SONCA\n",
      "202: OPHELIA\n",
      "203: HILARY\n",
      "204: NOT NAMED\n",
      "205: PHILIPPE\n",
      "206: NESAT\n",
      "207: HAITANG\n",
      "208: NALGAE\n",
      "209: IRWIN\n",
      "210: JOVA\n",
      "211: TWELVE\n",
      "212: BANYAN\n",
      "213: TWO\n",
      "214: RINA\n",
      "215: KEILA\n",
      "216: FOUR\n",
      "217: SEAN\n",
      "218: KENNETH\n",
      "219: FIVE\n",
      "220: ALENGA\n",
      "221: WASHI\n",
      "222: UNNAMED\n",
      "223: GRANT\n",
      "224: THANE\n",
      "225: BENILDE\n",
      "226: CHANDA\n",
      "227: HEIDI\n",
      "228: DANDO\n",
      "229: ETHEL\n",
      "230: FUNSO\n",
      "231: IGGY\n",
      "232: JASMINE\n",
      "233: CYRIL\n",
      "234: GIOVANNA\n",
      "235: HILWA\n",
      "236: IRINA\n",
      "237: JONI:KOJI\n",
      "238: LUA\n",
      "239: PAKHAR\n",
      "240: DAPHNE\n",
      "241: ALETTA\n",
      "242: ALBERTO\n",
      "243: SANVU\n",
      "244: BUD\n",
      "245: BERYL\n",
      "246: MAWAR\n",
      "247: KUENA\n",
      "248: GUCHOL\n",
      "249: CARLOTTA\n",
      "250: TALIM\n",
      "251: CHRIS\n",
      "252: DEBBY\n",
      "253: DOKSURI\n",
      "254: DANIEL\n",
      "255: EMILIA\n",
      "256: FABIO\n",
      "257: KHANUN\n",
      "258: VICENTE\n",
      "259: SAOLA\n",
      "260: DAMREY\n",
      "261: ERNESTO\n",
      "262: HAIKUI\n",
      "263: FLORENCE\n",
      "264: KIROGI\n",
      "265: GILMA\n",
      "266: HELENE\n",
      "267: KAI-TAK\n",
      "268: HECTOR\n",
      "269: GORDON\n",
      "270: TEMBIN\n",
      "271: BOLAVEN\n",
      "272: ISAAC\n",
      "273: JOYCE\n",
      "274: ILEANA\n",
      "275: LESLIE\n",
      "276: KIRK\n",
      "277: MICHAEL\n",
      "278: JOHN\n",
      "279: SANBA\n",
      "280: NADINE\n",
      "281: KRISTY\n",
      "282: LANE\n",
      "283: JELAWAT\n",
      "284: MIRIAM\n",
      "285: EWINIAR\n",
      "286: NORMAN\n",
      "287: GAEMI\n",
      "288: MALIKSI\n",
      "289: OSCAR\n",
      "290: PRAPIROON\n",
      "291: OLIVIA\n",
      "292: NOT NAMED\n",
      "293: PATTY\n",
      "294: ANAIS\n",
      "295: RAFAEL\n",
      "296: MARIA\n",
      "297: PAUL\n",
      "298: SON-TINH\n",
      "299: SANDY\n",
      "300: TONY\n",
      "301: MURJAN\n",
      "302: NILAM\n",
      "303: ROSA\n",
      "304: THREE\n",
      "305: BOLDWIN\n",
      "306: BOPHA\n",
      "307: CLAUDIA\n",
      "308: EVAN\n",
      "309: FOUR\n",
      "310: WUKONG\n",
      "311: DUMILE\n",
      "312: FREDA\n",
      "313: MITCHELL\n",
      "314: SONAMU\n",
      "315: NARELLE\n",
      "316: EMANG\n",
      "317: OSWALD\n",
      "318: GARRY\n",
      "319: PETA\n",
      "320: FELLENG\n",
      "321: HALEY\n",
      "322: GINO\n",
      "323: HARUNA\n",
      "324: SHANSHAN\n",
      "325: RUSTY\n",
      "326: SANDRA\n",
      "327: TIM\n",
      "328: IMELDA\n",
      "329: VICTORIA\n",
      "330: ZANE\n",
      "331: JAMALA\n",
      "332: MAHASEN:VIYARU\n",
      "333: ALVIN\n",
      "334: BARBARA\n",
      "335: NOT NAMED\n",
      "336: ANDREA\n",
      "337: YAGI\n",
      "338: LEEPI\n",
      "339: BARRY\n",
      "340: BEBINCA\n",
      "341: COSME\n",
      "342: RUMBIA\n",
      "343: DALILA\n",
      "344: ERICK\n",
      "345: SOULIK\n",
      "346: CHANTAL\n",
      "347: CIMARON\n",
      "348: DORIAN\n",
      "349: FLOSSIE\n",
      "350: JEBI\n",
      "351: GIL\n",
      "352: NOT NAMED\n",
      "353: HENRIETTE\n",
      "354: MANGKHUT\n",
      "355: UTOR\n",
      "356: THREE\n",
      "357: UNALA\n",
      "358: PEWA\n",
      "359: ERIN\n",
      "360: TRAMI\n",
      "361: IVO\n",
      "362: NOT NAMED\n",
      "363: KONG-REY\n",
      "364: FERNAND\n",
      "365: JULIETTE\n",
      "366: YUTU\n",
      "367: KIKO\n",
      "368: TORAJI\n",
      "369: GABRIELLE\n",
      "370: LORENA\n",
      "371: EIGHT\n",
      "372: HUMBERTO\n",
      "373: INGRID\n",
      "374: MAN-YI\n",
      "375: MANUEL\n",
      "376: USAGI\n",
      "377: PABUK\n",
      "378: WUTIP\n",
      "379: JERRY\n",
      "380: FITOW\n",
      "381: SEPAT\n",
      "382: DANAS\n",
      "383: KAREN\n",
      "384: NARDA\n",
      "385: PHAILIN\n",
      "386: NARI\n",
      "387: WIPHA\n",
      "388: OCTAVE\n",
      "389: PRISCILLA\n",
      "390: FRANCISCO\n",
      "391: LEKIMA\n",
      "392: RAYMOND\n",
      "393: LORENZO\n",
      "394: 0120132014:ONE\n",
      "395: KROSA\n",
      "396: TD:THIRTY\n",
      "397: SONIA\n",
      "398: HAIYAN\n",
      "399: THREE\n",
      "400: PODUL\n",
      "401: MELISSA\n",
      "402: HELEN\n",
      "403: LEHAR\n",
      "404: ALESSIA\n",
      "405: INVEST:UNNAMED\n",
      "406: MADI\n",
      "407: AMARA\n",
      "408: BRUCE\n",
      "409: CHRISTINE\n",
      "410: BEJISA\n",
      "411: ONE\n",
      "412: IAN\n",
      "413: COLIN\n",
      "414: LINGLING\n",
      "415: DELIWE\n",
      "416: JUNE\n",
      "417: JUNE\n",
      "418: DYLAN\n",
      "419: KAJIKI\n",
      "420: FLETCHER\n",
      "421: EDNA\n",
      "422: EDILSON\n",
      "423: FOBANE\n",
      "424: GUITO\n",
      "425: KOFI\n",
      "426: FAXAI\n",
      "427: HADI\n",
      "428: GILLIAN\n",
      "429: LUSI\n",
      "430: MIKE\n",
      "431: MIKE\n",
      "432: HELLEN\n",
      "433: ITA\n",
      "434: PEIPAH\n",
      "435: IVANOE\n",
      "436: JACK\n",
      "437: TAPAH\n",
      "438: NOT NAMED\n",
      "439: AMANDA\n",
      "440: BORIS\n",
      "441: NANAUK\n",
      "442: CRISTINA\n",
      "443: MITAG\n",
      "444: NOT NAMED\n",
      "445: HAGIBIS\n",
      "446: DOUGLAS\n",
      "447: ARTHUR\n",
      "448: ELIDA\n",
      "449: NEOGURI\n",
      "450: FAUSTO\n",
      "451: RAMMASUN\n",
      "452: WALI\n",
      "453: MATMO\n",
      "454: TWO\n",
      "455: NOT NAMED\n",
      "456: GENEVIEVE\n",
      "457: HERNAN\n",
      "458: HALONG\n",
      "459: NAKRI\n",
      "460: BERTHA\n",
      "461: ISELLE\n",
      "462: JULIO\n",
      "463: NOT NAMED\n",
      "464: KARINA\n",
      "465: LOWELL\n",
      "466: MARIE\n",
      "467: CRISTOBAL\n",
      "468: DOLLY\n",
      "469: NORBERT\n",
      "470: FENGSHEN\n",
      "471: SIXTEEN\n",
      "472: ODILE\n",
      "473: KALMAEGI\n",
      "474: EDOUARD\n",
      "475: POLO\n",
      "476: FUNG-WONG\n",
      "477: RACHEL\n",
      "478: KAMMURI\n",
      "479: PHANFONE\n",
      "480: SIMON\n",
      "481: VONGFONG\n",
      "482: HUD HUD:HUDHUD\n",
      "483: FAY\n",
      "484: ANA\n",
      "485: GONZALO\n",
      "486: TRUDY\n",
      "487: HANNA:INVEST\n",
      "488: NILOFAR\n",
      "489: VANCE\n",
      "490: NURI\n",
      "491: FIVE\n",
      "492: SINLAKU\n",
      "493: HAGUPIT\n",
      "494: KATE\n",
      "495: JANGMI\n",
      "496: LAM\n",
      "497: MARCIA\n",
      "498: OLWYN\n",
      "499: QUANG\n"
     ]
    }
   ],
   "source": [
    "idxs = []\n",
    "count = 0\n",
    "for i in range(500, 0, -1):\n",
    "    idx = ds.dimensions['storm'].size-i\n",
    "    # extract storm name\n",
    "    storm_name = np.array_str(NC.chartostring(ds.variables['name'][idx,:]))[2:-1]\n",
    "    print(\"{}: {}\".format(count, storm_name))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## find all storms that came within 200 miles of Hawaii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import (\n",
    "    Map, Marker, TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle,\n",
    "    CircleMarker, GeoJSON, DrawControl,\n",
    "    FeatureGroup\n",
    ")\n",
    "\n",
    "# bbox around the hawaiian islands\n",
    "hi_bbox = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [\n",
    "              -171.03515625,\n",
    "              6.926426847059551\n",
    "            ],\n",
    "            [\n",
    "              -171.03515625,\n",
    "              33.797408767572485\n",
    "            ],\n",
    "            [\n",
    "              -144.580078125,\n",
    "              33.797408767572485\n",
    "            ],\n",
    "            [\n",
    "              -144.580078125,\n",
    "              6.926426847059551\n",
    "            ],\n",
    "            [\n",
    "              -171.03515625,\n",
    "              6.926426847059551\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# center map over hawaii\n",
    "center = [20, -157]\n",
    "\n",
    "# draw map\n",
    "m = Map(center=center, zoom=4)\n",
    "g = GeoJSON(data=hi_bbox)\n",
    "m.add_layer(g)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with fake hurricane tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fake hurricane track\n",
    "fake_hurr_track1 = {\n",
    "    \"type\": \"LineString\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            -151.2158203125,\n",
    "            19.518375478601566\n",
    "        ],\n",
    "        [\n",
    "            -154.1162109375,\n",
    "            20.858811790867687\n",
    "        ],\n",
    "        [\n",
    "            -155.72021484375,\n",
    "            21.12549763660628\n",
    "        ],\n",
    "        [\n",
    "            -157.6318359375,\n",
    "            22.553147478403194\n",
    "        ],\n",
    "        [\n",
    "            -158.70849609375,\n",
    "            24.407137917727653\n",
    "        ],\n",
    "        [\n",
    "            -158.9501953125,\n",
    "            25.661333498952683\n",
    "        ],\n",
    "        [\n",
    "            -158.203125,\n",
    "            27.527758206861886\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "#f = GeoJSON(data=fake_hurr_track1)\n",
    "#m.add_layer(f)\n",
    "\n",
    "fake_hurr_track2 = {\n",
    "    \"type\": \"LineString\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            -114.60937499999999,\n",
    "            12.21118019150401\n",
    "        ],\n",
    "        [\n",
    "            -123.74999999999999,\n",
    "            18.47960905583197\n",
    "        ],\n",
    "        [\n",
    "            -135.87890625,\n",
    "            23.241346102386135\n",
    "        ],\n",
    "        [\n",
    "            -147.12890625,\n",
    "            26.58852714730864\n",
    "        ],\n",
    "        [\n",
    "            -159.78515624999997,\n",
    "            29.38217507514529\n",
    "        ],\n",
    "        [\n",
    "            -166.11328125,\n",
    "            27.527758206861886\n",
    "        ],\n",
    "        [\n",
    "            -167.6953125,\n",
    "            17.308687886770034\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "#f2 = GeoJSON(data=fake_hurr_track2)\n",
    "#m.add_layer(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter hurricanes that crossed HI bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr, osr\n",
    "gdal.UseExceptions()\n",
    "\n",
    "# set GDAL error handler function\n",
    "def gdal_error_handler(err_class, err_num, err_msg):\n",
    "    errtype = {\n",
    "            gdal.CE_None:'None',\n",
    "            gdal.CE_Debug:'Debug',\n",
    "            gdal.CE_Warning:'Warning',\n",
    "            gdal.CE_Failure:'Failure',\n",
    "            gdal.CE_Fatal:'Fatal'\n",
    "    }\n",
    "    err_msg = err_msg.replace('\\n',' ')\n",
    "    err_class = errtype.get(err_class, 'None')\n",
    "    print('Error Number: %s' % (err_num))\n",
    "    print('Error Type: %s' % (err_class))\n",
    "    print('Error Message: %s' % (err_msg))\n",
    "    \n",
    "#gdal.PushErrorHandler(gdal_error_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259451932941.54004\n",
      "1867252515472.281\n"
     ]
    }
   ],
   "source": [
    "# geometries are in WGS84 lat/lon projection\n",
    "src_srs = osr.SpatialReference()\n",
    "src_srs.SetWellKnownGeogCS(\"WGS84\")\n",
    "\n",
    "# use projection with unit as meters\n",
    "tgt_srs = osr.SpatialReference()\n",
    "tgt_srs.ImportFromEPSG(3857)\n",
    "\n",
    "# create transformer\n",
    "transform = osr.CoordinateTransformation(src_srs, tgt_srs)\n",
    "\n",
    "# get gdal geometries\n",
    "hi_bbox_geom = ogr.CreateGeometryFromJson(json.dumps(hi_bbox))\n",
    "hi_bbox_geom.Transform(transform)\n",
    "fake_hurr_track1_geom = ogr.CreateGeometryFromJson(json.dumps(fake_hurr_track1))\n",
    "fake_hurr_track1_geom.Transform(transform)\n",
    "print(hi_bbox_geom.Intersection(fake_hurr_track1_geom).GetArea()) # in square meters\n",
    "fake_hurr_track2_geom = ogr.CreateGeometryFromJson(json.dumps(fake_hurr_track2))\n",
    "fake_hurr_track2_geom.Transform(transform)\n",
    "print(hi_bbox_geom.Intersection(fake_hurr_track2_geom).GetArea()) # in square meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "\n",
    "# set styles\n",
    "style = {\n",
    "    \"color\": \"red\",\n",
    "    \"weight\": 1,\n",
    "}\n",
    "hover_style = {\n",
    "    \"weight\": 5,\n",
    "}\n",
    "\n",
    "# hover handler\n",
    "def hover_handler(event=None, id=None, properties=None):\n",
    "    sys.stdout.write(\"\\r\" + properties['msg'])\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# show map    \n",
    "m = Map(center=center, zoom=4)\n",
    "g = GeoJSON(data=hi_bbox)\n",
    "m.add_layer(g)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "int8 genesis_basin(storm)\n",
      "    long_name: Basin of genesis\n",
      "    units:  \n",
      "    key: 0 = NA - North Atlantic\n",
      "1 = SA - South Atlantic\n",
      "2 = WP - West Pacific\n",
      "3 = EP - East Pacific\n",
      "4 = SP - South Pacific\n",
      "5 = NI - North Indian\n",
      "6 = SI - South Indian\n",
      "7 = AS - Arabian Sea\n",
      "8 = BB - Bay of Bengal\n",
      "9 = EA - Eastern Australia\n",
      "10 = WA - Western Australia\n",
      "11 = CP - Central Pacific\n",
      "12 = CS - Carribbean Sea\n",
      "13 = GM - Gulf of Mexico\n",
      "14 = MM - Missing\n",
      "    Note: Based on where the storm began\n",
      "unlimited dimensions: storm\n",
      "current shape = (7152,)\n",
      "filling off\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ErfaWarning: ERFA function \"d2dtf\" yielded 1 of \"dubious year (Note 5)\" [astropy._erfa.core]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 storms that crossed hi_bbox\n"
     ]
    }
   ],
   "source": [
    "print(ds.variables['genesis_basin'])\n",
    "#print(ds.variables['lon_wmo'])\n",
    "\n",
    "# go through each hurricane get ones that crossed HI bbox\n",
    "crossed = []\n",
    "for i in range(ds.dimensions['storm'].size):\n",
    "    \n",
    "    # filter only storms that began in east pacific\n",
    "    if ds.variables['genesis_basin'][i] != 3: continue\n",
    "    \n",
    "    # get variables for storm\n",
    "    storm_sn = np.array_str(NC.chartostring(ds.variables['storm_sn'][i,:]))[2:-1]\n",
    "    storm_name = np.array_str(NC.chartostring(ds.variables['name'][i,:]))[2:-1]\n",
    "    obs = ds.variables['numObs'][i]\n",
    "    genesis_basin = ds.variables['genesis_basin'][i]\n",
    "    times = Time(ds.variables['time_wmo'][i,:obs-1], format='mjd', scale='utc')\n",
    "    #print(\"{}\".format(times.iso))\n",
    "    lats = ds.variables['lat_wmo'][i,:obs-1]\n",
    "    lons = ds.variables['lon_wmo'][i,:obs-1]\n",
    "    lons[np.where(lons > 0)] -= 360. # handle wrapping issue\n",
    "    landfall = (ds.variables['landfall'][i,:obs-1] == 0).any()\n",
    "    \n",
    "    # skip if there are 2 or less observations\n",
    "    if obs <= 2: continue\n",
    "        \n",
    "    # create GeoJSON\n",
    "    ls = { \n",
    "        \"type\": \"LineString\",\n",
    "        \"coordinates\": np.dstack((lons, lats))[0].tolist(),\n",
    "    }\n",
    "    \n",
    "    # get gdal geometry\n",
    "    ls_geom = ogr.CreateGeometryFromJson(json.dumps(ls))\n",
    "    ls_geom.Transform(transform)\n",
    "    \n",
    "    # get intersection\n",
    "    #intersect_area = hi_bbox_geom.Intersection(ls_geom).GetArea()\n",
    "    #intersect_area = 1.0\n",
    "    #if intersect_area > 0.0:\n",
    "    if landfall == True:\n",
    "        msg = \"{} {} {} {} {} {} {} {}\".format(i, storm_sn, storm_name,\n",
    "                                               times[0].iso, obs,\n",
    "                                               genesis_basin,\n",
    "                                               intersect_area,\n",
    "                                               landfall)\n",
    "        ls_feature = { \n",
    "            \"type\": \"Feature\",\n",
    "            \"properties\": { \"msg\": msg },\n",
    "            \"geometry\": ls,\n",
    "        }\n",
    "        l = GeoJSON(data=ls_feature, style=style, hover_style=hover_style)\n",
    "        l.on_hover(hover_handler)\n",
    "        m.add_layer(l)\n",
    "        crossed.append(i)\n",
    "        \n",
    "print(\"Found {} storms that crossed hi_bbox\".format(len(crossed)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "0b2d7ccd10fd4494a05fe8555cb54dca": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "0cd56a7c34aa4702b6f4413123f27f66": {
     "views": [
      {
       "cell_index": 13
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
